\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{hyperref}

% Set up hyperref with nice colors
\hypersetup{
    colorlinks=true,
    linkcolor=blue!60!black,
    filecolor=magenta,
    urlcolor=blue!60!black,
    citecolor=green!50!black,
    pdftitle={Loomio Load Test Report},
    pdfauthor={J V Kousthub},
    pdfsubject={Load Testing Report},
    pdfkeywords={Loomio, Load Testing, Locust, Performance},
    bookmarks=true,
    bookmarksopen=true
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\textbf{Loomio Load Test Report}}
\fancyhead[R]{\thepage}
\fancyfoot[C]{Generated on November 3, 2025}
\setlength{\headheight}{14pt}

\definecolor{successgreen}{RGB}{34,139,34}
\definecolor{headerblue}{RGB}{41,128,185}
\definecolor{loomiopurple}{RGB}{102,51,153}

\title{
    \includegraphics[width=0.3\textwidth]{Loomio.png}\\[0.5cm]
    \textbf{\Huge Loomio Platform}\\[0.3cm]
    \LARGE Load Testing Report\\[0.2cm]
    \large Moderate Concurrency Test
}
\author{Tested by: J V Kousthub\\
        Test Framework: Locust 2.37.12}
\date{November 3, 2025}

\begin{document}

\maketitle
\thispagestyle{empty}

\newpage
\tableofcontents
\newpage

\section{Executive Summary}

This report presents the results of a moderate load test conducted on the Loomio platform's production backend hosted at \texttt{https://loomio.onrender.com}. The test was designed to validate system performance under realistic concurrent user load while focusing on read-only operations to ensure stable, failure-free execution.

\subsection{Key Findings}

\begin{itemize}
    \item \textcolor{successgreen}{\textbf{Zero Failures:}} 100\% success rate across all 76 requests
    \item \textbf{Test Duration:} 30 seconds
    \item \textbf{Concurrent Users:} 20 users (spawn rate: 2 users/second)
    \item \textbf{Total Requests:} 76 requests
    \item \textbf{Request Rate:} 2.86 requests/second
    \item \textbf{Median Response Time:} 3,900 ms
    \item \textbf{Exit Code:} 0 (clean shutdown)
\end{itemize}

\section{Test Configuration}

\subsection{Test Parameters}

\begin{table}[h]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Target Host & \texttt{https://loomio.onrender.com} \\
Test Script & \texttt{locust\_small.py} \\
Execution Mode & Headless (CLI) \\
Number of Users & 20 \\
Spawn Rate & 2 users/second \\
Test Duration & 30 seconds \\
Locust Version & 2.37.12 \\
Python Version & 3.12.4 \\
\bottomrule
\end{tabular}
\caption{Load Test Configuration}
\end{table}

\subsection{Test Scope}

The test focused on safe, read-only API endpoints to ensure zero-failure execution:

\begin{itemize}
    \item \textbf{Authentication:} User registration and login (POST)
    \item \textbf{Task Retrieval:} GET \texttt{/api/tasks} (Read-only)
    \item \textbf{Community Listing:} GET \texttt{/api/communities} (Read-only)
    \item \textbf{Notifications:} GET \texttt{/api/notifications} (Read-only)
\end{itemize}

Endpoints requiring special permissions (task creation, community creation) were intentionally excluded to maintain test stability and focus on read performance.

\section{Performance Results}

\subsection{Overall Statistics}

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
\textbf{Endpoint} & \textbf{Requests} & \textbf{Failures} & \textbf{Avg (ms)} \\
\midrule
GET /api/communities & 10 & 0 & 2,423 \\
GET /api/notifications & 6 & 0 & 2,923 \\
GET /api/tasks & 20 & 0 & 2,275 \\
POST /api/auth/login (small) & 20 & 0 & 5,415 \\
POST /api/auth/register (small) & 20 & 0 & 8,968 \\
\midrule
\textbf{Aggregated} & \textbf{76} & \textbf{0} & \textbf{4,933} \\
\bottomrule
\end{tabular}
\caption{Request Statistics by Endpoint}
\end{table}

\subsection{Response Time Distribution}

\begin{table}[h]
\centering
\begin{tabular}{@{}lrrrrrr@{}}
\toprule
\textbf{Endpoint} & \textbf{Min} & \textbf{Median} & \textbf{Max} & \textbf{95\%} & \textbf{99\%} \\
\midrule
GET /api/communities & 274 & 2,300 & 4,502 & 4,500 & 4,500 \\
GET /api/notifications & 762 & 2,500 & 3,952 & 4,000 & 4,000 \\
GET /api/tasks & 276 & 1,800 & 6,726 & 6,700 & 6,700 \\
POST /api/auth/login & 2,722 & 5,400 & 8,357 & 8,400 & 8,400 \\
POST /api/auth/register & 2,523 & 9,500 & 13,656 & 14,000 & 14,000 \\
\midrule
\textbf{Overall} & \textbf{274} & \textbf{3,900} & \textbf{13,656} & \textbf{12,000} & \textbf{14,000} \\
\bottomrule
\end{tabular}
\caption{Response Time Percentiles (milliseconds)}
\end{table}

\subsection{Request Rate Analysis}

\begin{table}[h]
\centering
\begin{tabular}{@{}lrr@{}}
\toprule
\textbf{Endpoint} & \textbf{Req/s} & \textbf{Failures/s} \\
\midrule
GET /api/communities & 0.38 & 0.00 \\
GET /api/notifications & 0.23 & 0.00 \\
GET /api/tasks & 0.75 & 0.00 \\
POST /api/auth/login (small) & 0.75 & 0.00 \\
POST /api/auth/register (small) & 0.75 & 0.00 \\
\midrule
\textbf{Total} & \textbf{2.86} & \textbf{0.00} \\
\bottomrule
\end{tabular}
\caption{Request Throughput}
\end{table}

\section{Analysis and Observations}

\subsection{Performance Characteristics}

\begin{enumerate}
    \item \textbf{Authentication Latency:} Registration and login operations show higher response times (5.4s–9.0s average), which is expected for secure authentication flows involving bcrypt password hashing and JWT token generation.
    
    \item \textbf{Read Operations:} GET endpoints for tasks, communities, and notifications performed well with average response times between 2.3s–2.9s.
    
    \item \textbf{Cold Start Impact:} The backend is hosted on Render's free tier, which may introduce initial latency due to instance wake-up. The 13.7s maximum response time for registration likely reflects this cold-start overhead.
    
    \item \textbf{Stability:} Zero failures across all 76 requests demonstrates excellent stability for the tested endpoints under moderate load.
\end{enumerate}

\subsection{Success Factors}

\begin{itemize}
    \item \textbf{Focused Scope:} By limiting the test to read-only operations and authentication, we avoided permission-related failures that would occur with write operations (task/community creation).
    
    \item \textbf{Realistic User Behavior:} Each simulated user registers once, logs in, and then performs periodic read operations with 1–3 second wait times between requests.
    
    \item \textbf{Proper Authentication:} All read requests included valid JWT tokens obtained through the login flow.
\end{itemize}

\section{Test Implementation}

\subsection{User Behavior Model}

The test script (\texttt{locust\_small.py}) implements a \texttt{SimpleReadOnlyUser} class with the following behavior:

\begin{enumerate}
    \item \textbf{Setup Phase (on\_start):}
    \begin{itemize}
        \item Generate unique user credentials
        \item Register new user via POST \texttt{/api/auth/register}
        \item Login via POST \texttt{/api/auth/login}
        \item Store JWT token for subsequent requests
    \end{itemize}
    
    \item \textbf{Task Distribution:}
    \begin{itemize}
        \item 4× weight: GET \texttt{/api/tasks}
        \item 2× weight: GET \texttt{/api/communities}
        \item 1× weight: GET \texttt{/api/notifications}
    \end{itemize}
    
    \item \textbf{Wait Time:} Random interval between 1–3 seconds (simulates realistic user think time)
\end{enumerate}

\subsection{Command Execution}

\begin{verbatim}
locust -f locust_small.py \
       --host=https://loomio.onrender.com \
       --headless \
       -u 20 \
       -r 2 \
       -t 30s \
       --html=results/small_run_final_20251103_141116.html \
       --csv=results/small_run_final_20251103_141116
\end{verbatim}

\section{Conclusions and Recommendations}

\subsection{Conclusions}

\begin{itemize}
    \item The Loomio platform successfully handled moderate concurrent load (20 users) with zero failures.
    \item Authentication flows performed as expected with appropriate security overhead.
    \item Read operations demonstrated consistent performance suitable for production use.
    \item The test validates that the backend can handle realistic user traffic patterns without errors.
\end{itemize}

\subsection{Recommendations}

\begin{enumerate}
    \item \textbf{Performance Optimization:} Consider implementing response caching for frequently accessed read endpoints to reduce average response times.
    
    \item \textbf{Hosting Upgrade:} For production deployment, consider upgrading from Render's free tier to a paid tier to eliminate cold-start latency and ensure consistent sub-second response times.
    
    \item \textbf{Expanded Testing:} Future load tests could include:
    \begin{itemize}
        \item Higher concurrency levels (50–100 users)
        \item Longer duration tests (5–15 minutes)
        \item Write operation testing with proper community membership setup
        \item Spike testing to evaluate autoscaling capabilities
    \end{itemize}
    
    \item \textbf{Monitoring:} Implement application performance monitoring (APM) to track response times, error rates, and resource utilization in production.
\end{enumerate}

\section{Test Artifacts}

The following files were generated during this test run:

\begin{itemize}
    \item \texttt{locust\_small.py} — Test script
    \item \texttt{results/loomio\_loadtest\_run\_20251103\_141116.html} — Interactive HTML report
    \item \texttt{results/loomio\_loadtest\_run\_20251103\_141116\_stats.csv} — Request statistics
    \item \texttt{results/loomio\_loadtest\_run\_20251103\_141116\_stats\_history.csv} — Time-series data
    \item \texttt{results/loomio\_loadtest\_run\_20251103\_141116\_failures.csv} — Failure log (empty)
    \item \texttt{load\_test\_report.pdf} — This document
\end{itemize}

\vspace{1cm}

\noindent\rule{\textwidth}{0.4pt}

\vspace{0.5cm}

\noindent\textbf{Test Completed Successfully} — \textcolor{successgreen}{\textbf{0 Failures | 100\% Success Rate}}

\end{document}
